#############################################
####==UNOISE 3 SAeDNA ascidian analysis==####
####==== Luke E. Holman====26.01.2021====####
#############################################
##Note we are using the docker image 'lukeholman/dockedna:0.2'


####====0.0 Packages & parameters====####
library(metabarTOAD)
cat(file="log.txt", date(), sep="\n")
max_diffs <- 15
pct_id <- 80
Qfiltermaxee <- 1.0

####====1.0 UnZip & Count====####

#read in files to be worked on
files <- list.files("1.rawreads/",pattern="*.gz")

#unzip files if they are .gz type
for (i in files){
  system2('/dockeDNAsoftware/pigz',args=paste("-d 1.rawreads/",i))
}

#Count up those fastq
files <- list.files("1.rawreads/",pattern="*.fastq")
rawdatastats <- data.frame(ID=files,Numberofreads=rep(NA,length(files)))
for (i in files){
  rawdatastats$Numberofreads[rawdatastats$ID==i] <-FastqCount(paste0("1.rawreads/",i))
}
   
####====2.0 Merge & Count====####   
   
#Now lets merge the reads
 MergeReads(usearchdest = "/dockeDNAsoftware/usearch11.0.667_i86linux32")

#Lets count the merged reads
mergedreadcount <- sapply(list.files("2.mergedreads",pattern=".fastq",full.names = TRUE),FastqCount)

####====3.0 Primer Strip & Count====####   

PrimerStrip(PrimerF = "NNNNNNGGWACWGGWTGAACWGTWTAYCCYCC",
            PrimerR = "TAIACYTCIGGRTGICCRAARAAYCA",
            MinLen = 303,
            MaxLen = 323,
            cutadaptdest = "cutadapt",
            ncores=4)

strippedreadcount <- sapply(list.files("3.strippedreads",pattern=".fastq",full.names = TRUE),FastqCount)
strippedreadcount 

####====4.0 Pool N Filter====#### 
PoolNFilterReads(vsearchdest="/dockeDNAsoftware/vsearch-2.15.1-linux-x86_64")

####====5.0 Cluster ASVs @ alpha 5====#### 

#bash 

usearch11.0.667_i86linux32 -unoise3 ~/scratch/SAeDNAasc/4.pooledsamples/AllSamples.pooled.ST.QF.fastq -minsize 2 -unoise_alpha 5 -zotus ~/scratch/SAeDNAasc/5.OTUs/unoise3OTUs.a5.fa -tabbedout ~/scratch/SAeDNAasc/5.OTUs/temp.unoise3.txt
 
 
 